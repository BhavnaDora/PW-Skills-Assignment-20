{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30013dd2-6cec-4eac-b3f8-2c202d1192e5",
   "metadata": {},
   "source": [
    "#### (1)-\n",
    "##### Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. \n",
    "##### We can maunally copy paste data from websites into our files but when we need millions of data, this manual process fails. For this reason web scraping is used. It automates the process and large volumes of data are extracted in no time.\n",
    "##### Web scraping is used for price monitoring and market research by companies. web scraping is also helpful in monitoring news, email marketing, sentiment analysis etc.\n",
    "##### Areas where web scraping is used- eCommerce, Sports analytics, Real estate, Social media etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c3a413-d08b-480f-95fe-b320ce0cd01b",
   "metadata": {},
   "source": [
    "#### (2)-\n",
    "##### The different methods or tools used for web scraping are- \n",
    "##### Requests- it is a python library used for making HTTP requests like GET, POST etc. \n",
    "##### BeautifulSoup- it creates a parse tree that is used to extract data from HTML \n",
    "##### Selenium- used for scraping data from dynamically populated websites\n",
    "##### Scrapy- it provides spider bots that can crawl multiple websites and extract data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2bf6c5-2670-49b0-a22a-038cc4ad1d37",
   "metadata": {},
   "source": [
    "#### (3)- \n",
    "##### BeautifulSoup is perhaps the most widely used Python library for web scraping. It creates a parse tree for parsing HTML and XML documents and makes them a bit more structured. It helps us to pull particular content from a web page, remove the html markup and save the information. Beautiful Soup automatically converts incoming documents to Unicode and outgoing documents to UTF-8. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915c5753-5351-4ec9-afc7-be256dad7df7",
   "metadata": {},
   "source": [
    "#### (4)-\n",
    "##### Flask is used in the web scraping project because it is fast, lightweight and beginner's friendly web framework and it uses WSGI toolkit Jinja2 template engine. In flask we can easily integrate MongoDB, we can install the necessary packages in a very less time. In flask we can easily push the application files to github. The app runs smoothly too and our flask lab acts as an excellent server. So for all these advantages flask is used for building web scraping project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f0ca9-0b35-48f5-ac93-ad2116200a1a",
   "metadata": {},
   "source": [
    "#### (5)-\n",
    "##### The AWS services that we used in this web scraping project are- Elastic Beanstalk and Code Pipeline\n",
    "##### Elastic Beanstalk- It is a service provided by AWS that provides a platform for deploying and scaling apllications. It takes our code and deploys it while provisioning the supporting architecture and compute resources required for our code to run.\n",
    "##### Code Pipeline- It is a continous delivery service that pulls code from github and deploys it to Elastic Beanstalk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
